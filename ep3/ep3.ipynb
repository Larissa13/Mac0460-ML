{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAC0460/5832 - Lista 3: Redes Neurais - MNIST\n",
    "\n",
    "### Data de Entrega: 23h55m do dia 23/06/2017\n",
    "\n",
    "##### Classificação de dígitos\n",
    "Os dataset para esta tarefa foi tirado da competição do kaggle de reconhecimento de dígitos (https://www.kaggle.com/c/digit-recognizer) e está disponível em http://vision.ime.usp.br/~caiomr/mac0460_5832/train.csv.gz. O dataset está sob a licença Creative Commons Attribution-Share Alike 3.0 license (https://creativecommons.org/licenses/by-sa/3.0/). O dataset foi zipado, mas os dados estão inalterados. Cada linha (amostra) do arquivo contém 785 colunas: a primeira informa o label da amostra e as outras 784 são os valores dos pixels da imagem (28 x 28) que representa o dígito.\n",
    "\n",
    "Q1. Projete uma rede neural para resolver o problema de classificação de dígitos. Baixe o arquivo train.csv.gz (link acima) e dezipe-o para a pasta data/. Verifique que as células abaixo executam com sucesso e exibem o resultado esperado. Utilize os pacotes de python tensorflow (https://www.tensorflow.org/) ou theano (http://deeplearning.net/software/theano/) para implementar sua rede neural. Escolha o que preferir/tiver mais familiaridade - ou o quiser passar a ter mais familiaridade :) - para definir sua rede neural. Usem a arquitetura 3-layer NN 300+100 hidden units (erro 3.05%), como descrito no site http://yann.lecun.com/exdb/mnist/index.html.\n",
    "\n",
    "\n",
    "Façam os três seguintes experimentos:\n",
    "\n",
    "1. Imagem original.\n",
    "2. Imagem amostrada com passo 1, isto é, reduz a imagem para 1/4 do número total de pixels.\n",
    "3. Imagem amostrada com passo 2, isto é, reduz a imagem para 1/16 do número total de pixels.\n",
    "\n",
    "\n",
    "Em cada experimento, execute os seguintes procedimentos:\n",
    "1. Compute a curva experimental de aprendizado (N = 5000, N = 10000, N = 15000, ... N = 35000), estimar o $E_{out}$ a partir das 7000 amostras não usadas.\n",
    "2. Para N = 35000 (isto é, separe 7000 amostras para validação), calcule o valor da precisão $\\epsilon = E_{out} - E_{in}$.\n",
    "3. Adote o valor de $\\epsilon$ calculado em 2; repita dez vezes o experimento de aprendizado para $N = 35000$ e 7000 amostras de validação (em cada experimento, escolha aleatoriamente entre as 42000 amostras 7000 para formar o conjunto de validação e as restantes para treinamento); calcule o $E_{out}$ para cada um dos experimentos; a partir dos $E_{out}$ calculados, estime o valor do parâmetro $\\delta$.\n",
    "4. Comente os resultados obtidos.\n",
    "\n",
    "Adote *learning rate* $\\eta = 0.001$.\n",
    "Para o item 3, lembre da equação $P(|E_{out}(h_{opt}) - E_{in}(h_{opt})| < \\epsilon) > 1 - \\delta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('data/train.csv', delimiter=',', skip_header=1).astype(np.dtype('uint8'))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  1\n",
      "Label:  0\n",
      "Label:  8\n"
     ]
    }
   ],
   "source": [
    "sample = data[0]\n",
    "print(\"Label: \", sample[0])\n",
    "plt.imshow(sample[1:].reshape((28,28)), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "sample = data[1]\n",
    "print(\"Label: \", sample[0])\n",
    "plt.imshow(sample[1:].reshape((28,28)), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "sample = data[20]\n",
    "print(\"Label: \", sample[0])\n",
    "plt.imshow(sample[1:].reshape((28,28)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "label_size = 10\n",
    "layer1_size = 300\n",
    "layer2_size = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_size = 35000\n",
    "display = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_t = np.zeros((data.shape[0], 10))\n",
    "labels_t[np.arange(data.shape[0]), data[:, 0].flatten()] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.136   0.148714\n",
      "0.833029   0.831286\n",
      "0.868943   0.867143\n",
      "0.876857   0.871714\n",
      "0.909886   0.899143\n",
      "0.909743   0.898143\n",
      "0.909714   0.894857\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.placeholder(tf.float32, shape=[None, input_size])\n",
    "label = tf.placeholder(tf.float32, shape=[None, label_size])\n",
    "\n",
    "def model(input1, input_size, label_size, layer1_size, layer2_size):\n",
    "    W0 = tf.Variable(tf.truncated_normal([input_size,layer1_size], stddev=0.1))\n",
    "    b0 = tf.Variable(tf.truncated_normal([layer1_size], stddev=0.1))\n",
    "    W1 = tf.Variable(tf.truncated_normal([layer1_size, layer2_size], stddev=0.1))\n",
    "    b1 = tf.Variable(tf.truncated_normal([layer2_size], stddev=0.1))\n",
    "    W2 = tf.Variable(tf.truncated_normal([layer2_size, label_size], stddev=0.1))\n",
    "    b2 = tf.Variable(tf.truncated_normal([label_size], stddev=0.1))\n",
    "    \n",
    "    layer1 = tf.add(tf.matmul(input1, W0), b0)\n",
    "    layer1 = tf.nn.relu(layer1)\n",
    "    layer2 = tf.add(tf.matmul(layer1, W1), b1)\n",
    "    layer2 = tf.nn.relu(layer2)\n",
    "    \n",
    "    output = tf.matmul(layer2, W2) + b2\n",
    "    return output\n",
    "\n",
    "apply_model = model(input1, input_size, label_size, layer1_size, layer2_size)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=apply_model, labels=label))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "correct_prediction = tf.equal(tf.argmax(apply_model, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "n_batches = training_size//batch_size\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={input1: data[i*batch_size:(i + 1)*batch_size, 1:],\n",
    "                                                          label: labels_t[i*batch_size:(i + 1)*batch_size, :]})\n",
    "        if (i*batch_size)%display == 0:\n",
    "            correct_input = sess.run(accuracy, feed_dict={input1: data[:training_size, 1:],\n",
    "                                                          label: labels_t[:training_size, :]})\n",
    "            correct_val = sess.run(accuracy, feed_dict={input1: data[training_size:, 1:],\n",
    "                                                          label: labels_t[training_size:, :]})\n",
    "            \n",
    "            print(correct_input, \" \", correct_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Q2. O método de aprendizado adotado na questão anterior inclui regularização? Caso afirmativo, como? Caso negativo, como formularia a inclusão da regularização e porque esse procedimento melhoraria o resultado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
